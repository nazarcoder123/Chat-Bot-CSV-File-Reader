{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers==4.4.2","metadata":{"execution":{"iopub.status.busy":"2023-08-17T09:17:21.574952Z","iopub.execute_input":"2023-08-17T09:17:21.575287Z","iopub.status.idle":"2023-08-17T09:17:42.568144Z","shell.execute_reply.started":"2023-08-17T09:17:21.575260Z","shell.execute_reply":"2023-08-17T09:17:42.566928Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m \u001b[31m[51 lines of output]\u001b[0m\n  \u001b[31m   \u001b[0m running bdist_wheel\n  \u001b[31m   \u001b[0m running build\n  \u001b[31m   \u001b[0m running build_py\n  \u001b[31m   \u001b[0m creating build\n  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310\n  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/tokenizers\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/__init__.py -> build/lib.linux-x86_64-cpython-310/tokenizers\n  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/tokenizers/models\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/models/__init__.py -> build/lib.linux-x86_64-cpython-310/tokenizers/models\n  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/tokenizers/decoders\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/decoders/__init__.py -> build/lib.linux-x86_64-cpython-310/tokenizers/decoders\n  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/tokenizers/normalizers\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/normalizers/__init__.py -> build/lib.linux-x86_64-cpython-310/tokenizers/normalizers\n  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/tokenizers/pre_tokenizers\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/pre_tokenizers/__init__.py -> build/lib.linux-x86_64-cpython-310/tokenizers/pre_tokenizers\n  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/tokenizers/processors\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/processors/__init__.py -> build/lib.linux-x86_64-cpython-310/tokenizers/processors\n  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/tokenizers/trainers\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/trainers/__init__.py -> build/lib.linux-x86_64-cpython-310/tokenizers/trainers\n  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/tokenizers/implementations\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/__init__.py -> build/lib.linux-x86_64-cpython-310/tokenizers/implementations\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/base_tokenizer.py -> build/lib.linux-x86_64-cpython-310/tokenizers/implementations\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/byte_level_bpe.py -> build/lib.linux-x86_64-cpython-310/tokenizers/implementations\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/sentencepiece_bpe.py -> build/lib.linux-x86_64-cpython-310/tokenizers/implementations\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/char_level_bpe.py -> build/lib.linux-x86_64-cpython-310/tokenizers/implementations\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/bert_wordpiece.py -> build/lib.linux-x86_64-cpython-310/tokenizers/implementations\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/implementations/sentencepiece_unigram.py -> build/lib.linux-x86_64-cpython-310/tokenizers/implementations\n  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/tokenizers/tools\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/tools/__init__.py -> build/lib.linux-x86_64-cpython-310/tokenizers/tools\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/tools/visualizer.py -> build/lib.linux-x86_64-cpython-310/tokenizers/tools\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/__init__.pyi -> build/lib.linux-x86_64-cpython-310/tokenizers\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/models/__init__.pyi -> build/lib.linux-x86_64-cpython-310/tokenizers/models\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/decoders/__init__.pyi -> build/lib.linux-x86_64-cpython-310/tokenizers/decoders\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/normalizers/__init__.pyi -> build/lib.linux-x86_64-cpython-310/tokenizers/normalizers\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/pre_tokenizers/__init__.pyi -> build/lib.linux-x86_64-cpython-310/tokenizers/pre_tokenizers\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/processors/__init__.pyi -> build/lib.linux-x86_64-cpython-310/tokenizers/processors\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/trainers/__init__.pyi -> build/lib.linux-x86_64-cpython-310/tokenizers/trainers\n  \u001b[31m   \u001b[0m copying py_src/tokenizers/tools/visualizer-styles.css -> build/lib.linux-x86_64-cpython-310/tokenizers/tools\n  \u001b[31m   \u001b[0m running build_ext\n  \u001b[31m   \u001b[0m running build_rust\n  \u001b[31m   \u001b[0m error: can't find Rust compiler\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m To update pip, run:\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m     pip install --upgrade pip\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m and then retry package installation.\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import torch\ntorch.__version__","metadata":{"execution":{"iopub.status.busy":"2023-08-17T09:17:49.895463Z","iopub.execute_input":"2023-08-17T09:17:49.896506Z","iopub.status.idle":"2023-08-17T09:17:52.955342Z","shell.execute_reply.started":"2023-08-17T09:17:49.896439Z","shell.execute_reply":"2023-08-17T09:17:52.954159Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'2.0.0'"},"metadata":{}}]},{"cell_type":"code","source":"!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html","metadata":{"execution":{"iopub.status.busy":"2023-08-17T09:17:54.675371Z","iopub.execute_input":"2023-08-17T09:17:54.676530Z","iopub.status.idle":"2023-08-17T09:29:22.040401Z","shell.execute_reply.started":"2023-08-17T09:17:54.676489Z","shell.execute_reply":"2023-08-17T09:29:22.039180Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Looking in links: https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\nCollecting torch-scatter\n  Downloading torch_scatter-2.1.1.tar.gz (107 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.6/107.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: torch-scatter\n  Building wheel for torch-scatter (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for torch-scatter: filename=torch_scatter-2.1.1-cp310-cp310-linux_x86_64.whl size=3538215 sha256=a851cb06e92d2282832819869bd412554a18199811be1f24b654c65b4d601700\n  Stored in directory: /root/.cache/pip/wheels/ef/67/58/6566a3b61c6ec0f2ca0c2c324cd035ef2955601f0fb3197d5f\nSuccessfully built torch-scatter\nInstalling collected packages: torch-scatter\nSuccessfully installed torch-scatter-2.1.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-08-17T09:29:22.043174Z","iopub.execute_input":"2023-08-17T09:29:22.043611Z","iopub.status.idle":"2023-08-17T09:29:34.036421Z","shell.execute_reply.started":"2023-08-17T09:29:22.043570Z","shell.execute_reply":"2023-08-17T09:29:34.035153Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import pipeline\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-08-17T09:29:55.676138Z","iopub.execute_input":"2023-08-17T09:29:55.676769Z","iopub.status.idle":"2023-08-17T09:30:07.273476Z","shell.execute_reply.started":"2023-08-17T09:29:55.676727Z","shell.execute_reply":"2023-08-17T09:30:07.272423Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"tqa = pipeline(task=\"table-question-answering\",model=\"google/tapas-base-finetuned-wtq\")","metadata":{"execution":{"iopub.status.busy":"2023-08-17T09:30:07.275492Z","iopub.execute_input":"2023-08-17T09:30:07.277400Z","iopub.status.idle":"2023-08-17T09:30:22.999886Z","shell.execute_reply.started":"2023-08-17T09:30:07.277362Z","shell.execute_reply":"2023-08-17T09:30:22.998911Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.66k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61c6b580fb81402e95bb5b5e5ff18a82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1d3f80a64724b85b93b09ce530c574d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/490 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f51594b8b5d4cea87a01ba238f88756"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/262k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"041d764a6b804812ae45bd196b679a75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/154 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"989b238d56484e26b8df679828d25e6f"}},"metadata":{}}]},{"cell_type":"code","source":"table=pd.read_csv(\"/kaggle/input/gpa-and-iq/gpa_iq.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-08-17T10:04:03.226784Z","iopub.execute_input":"2023-08-17T10:04:03.227182Z","iopub.status.idle":"2023-08-17T10:04:03.236008Z","shell.execute_reply.started":"2023-08-17T10:04:03.227148Z","shell.execute_reply":"2023-08-17T10:04:03.234895Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"table = table.astype(str)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T10:04:04.396111Z","iopub.execute_input":"2023-08-17T10:04:04.396737Z","iopub.status.idle":"2023-08-17T10:04:04.402130Z","shell.execute_reply.started":"2023-08-17T10:04:04.396699Z","shell.execute_reply":"2023-08-17T10:04:04.401011Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"table.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-17T10:04:05.616729Z","iopub.execute_input":"2023-08-17T10:04:05.617431Z","iopub.status.idle":"2023-08-17T10:04:05.632450Z","shell.execute_reply.started":"2023-08-17T10:04:05.617391Z","shell.execute_reply":"2023-08-17T10:04:05.631491Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"  obs    gpa   iq gender concept\n0   1   7.94  111      2      67\n1   2  8.292  107      2      43\n2   3  4.643  100      2      52\n3   4   7.47  107      2      66\n4   5  8.882  114      1      58","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>obs</th>\n      <th>gpa</th>\n      <th>iq</th>\n      <th>gender</th>\n      <th>concept</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>7.94</td>\n      <td>111</td>\n      <td>2</td>\n      <td>67</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>8.292</td>\n      <td>107</td>\n      <td>2</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>4.643</td>\n      <td>100</td>\n      <td>2</td>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>7.47</td>\n      <td>107</td>\n      <td>2</td>\n      <td>66</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>8.882</td>\n      <td>114</td>\n      <td>1</td>\n      <td>58</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"table.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-17T10:04:07.186130Z","iopub.execute_input":"2023-08-17T10:04:07.186524Z","iopub.status.idle":"2023-08-17T10:04:07.193196Z","shell.execute_reply.started":"2023-08-17T10:04:07.186487Z","shell.execute_reply":"2023-08-17T10:04:07.192090Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"(78, 5)"},"metadata":{}}]},{"cell_type":"code","source":"query = \"What is the maximum iq?\"\nprint(tqa(table=table,query=query)[\"answer\"])","metadata":{"execution":{"iopub.status.busy":"2023-08-17T10:06:44.356404Z","iopub.execute_input":"2023-08-17T10:06:44.356855Z","iopub.status.idle":"2023-08-17T10:06:45.535761Z","shell.execute_reply.started":"2023-08-17T10:06:44.356820Z","shell.execute_reply":"2023-08-17T10:06:45.534667Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"AVERAGE > 136\n","output_type":"stream"}]}]}